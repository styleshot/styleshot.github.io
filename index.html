<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>StyleShot</title>
<link href="./StyleShot_files/style.css" rel="stylesheet">
<script type="text/javascript" src="./StyleShot_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./StyleShot_files/jquery.js"></script>
</head>

<body>
<div class="content">
  <h1><strong>StyleShot: A SnapShot on Any Style</strong></h1>
  <p id="authors"><span>
  <a href=""></a></span>
  <a href="" style="pointer-events: none; text-decoration:none; color: black;">Junyao Gao<sup>1,2</sup></a>
  <a href="" style="pointer-events: none; text-decoration:none; color: black;">Yanchen Liu<sup>2</sup></a>
  <a href="" style="pointer-events: none; text-decoration:none; color: black;">Yanan Sun<sup>2,&Dagger;</sup></a>
  <a href="" style="pointer-events: none; text-decoration:none; color: black;">Yinhao Tang<sup>2</sup></a>
  <a href="" style="pointer-events: none; text-decoration:none; color: black;">Yanhong Zeng<sup>2</sup></a>
  <br>
  <a href="" style="pointer-events: none; text-decoration:none; color: black;">Kai Chen<sup>2*</sup></a>
  <a href="" style="pointer-events: none; text-decoration:none; color: black;">Cairong Zhao<sup>1*</sup></a>
<br>
    <br>
<p id="authors" style="margin-top: 10px;">
      <span style="font-size: 16px; margin-top: 0;">
        <sup>1</sup> Tongji University, <sup>2</sup> Shanghai AI Laboratory, <br>
        <sup>*</sup> Corresponding author, <sup>&Dagger;</sup> Project Leader
      </span> 
    </p>
  </span></p>
  <br>
<img src="./StyleShot_files/teaser.png" class="teaser-gif" style="width:100%;"><br>
  <h3 style="text-align:center"><em>Visualization results of <bf>StyleShot</bf> for text and image driven style transfer across six style reference images. Each stylized image is generated by StyleShot without test-time style-tuning, capturing numerous nuances such as colors, textures, illumination and layout.
</em></h3>
    <font size="+2">
          <p style="text-align: center;">
            <a href="http://arxiv.org/abs/2407.01414" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
	    <a href="https://github.com/open-mmlab/StyleShot" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="./StyleShot_files/styleshot.txt" target="_blank">[BibTeX]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/open-mmlab/StyleShot" target="_blank">[Dataset]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://openxlab.org.cn/apps/detail/lianchen/StyleShot" target="_blank">[Demo]</a>
          </p>
    </font>
</div>
<div class="content">
  <h2 style="text-align:center;"><strong>Abstract</strong></h2>
<p>In this paper, we show that, a good style representation is crucial and sufficient for generalized style transfer without test-time tuning. We achieve this through constructing a style-aware encoder and a well-organized style dataset called StyleGallery. With dedicated design for style learning, this style-aware encoder is trained to extract expressive style representation with decoupling training strategy, and StyleGallery enables the generalization ability. We further employ a content-retention encoder to enhance image-driven style transfer. We highlight that, our approach, named StyleShot, is simple yet effective in mimicking various desired styles, i.e., 3D, flat, abstract or even fine-grained styles, without test-time tuning. Rigorous experiments validate that, StyleShot achieves superior performance across a wide range of styles compared to existing state-of-the-art methods.</p>
</div>
<div class="content">
  <h2 style="text-align:center;"><strong>Method</strong></h2>
  <img class="summary-img" src="./StyleShot_files/framework.png" style="width:100%;"> <br>
<p>StyleShot is built on Stable Diffusion. To design a style encoder that specially extracts rich and expressive style embedding, our pipeline comprises a style transfer model with a style-aware encoder. Moreover, we proposed a content-fusion encoder to enhance the integration of content and style.</p>
</div>
<div class="content">
  <h2>Gallery</h2>
  <p>We present results on text and image-driven style transfer. Our StyleShot effectively captures a broad spectrum of style features, ranging from basic elements like colors and textures to intricate components like layout, structure, and shading. Transfer your own style with our <a href="https://github.com/open-mmlab/StyleShot">open source code</a> or <a href="https://openxlab.org.cn/apps/detail/lianchen/StyleShot">online demo</a>. </p>
  <h3>Text-driven style transfer</h3>
  <p>From left to right, Reference style image, ``A cat'', ``A dog'', ``A moose'', ``A chef preparing meals in kitchen'',  ``A house with a tree beside'', ''A wolf walking stealthily through the forest''.</p>
  <img class="summary-img" src="./StyleShot_files/text_gallery.png" style="width:100%;">
  <h3>Image-driven style transfer</h3>
  <img class="summary-img" src="./StyleShot_files/image_gallery.png" style="width:100%;">
</div>
<div class="content">
  <h2>Societal Impact</h2>
  <p>We recognize that StyleShot possesses the capability to replicate the styles of individual artists without their consent, and we advocate for the responsible usage of our technology.</p>
  <br>
</div>
<div class="content">
  <h2>BibTex</h2>
  <code> @article{gao2024styleshot,<br>
  &nbsp;&nbsp;title={StyleShot: A Snapshot on Any Style},<br>
  &nbsp;&nbsp;author={Junyao, Gao and Yanchen, Liu and Yanan, Sun and Yinhao, Tang and Yanhong, Zeng and Kai, Chen and Cairong, Zhao},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint arxiv:2407.01414},<br>
  &nbsp;&nbsp;year={2024}<br>
  } </code> 
</div>

<br><br>
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">                                                                                                                                   
      <!-- <div class="content"> -->
      The website template is taken from <a href="https://dreambooth.github.io/">dreambooth</a> project page.
      <!-- </div> -->
    </div>
  </div>
</footer>
<br><br>
</body>
</html>
